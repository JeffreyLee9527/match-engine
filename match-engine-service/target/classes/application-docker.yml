# Docker环境配置
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: ${SPRING_DATASOURCE_URL:jdbc:mysql://mysql:3306/spark_match_engine?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=Asia/Shanghai&allowPublicKeyRetrieval=true}
    username: ${SPRING_DATASOURCE_USERNAME:spark}
    password: ${SPRING_DATASOURCE_PASSWORD:spark}
  kafka:
    bootstrap-servers: ${SPRING_KAFKA_BOOTSTRAP_SERVERS:kafka:9092}
    consumer:
      group-id: match-engine-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      enable-auto-commit: false
      auto-offset-reset: earliest
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer

server:
  port: 8082

# Spring Boot Actuator配置
management:
  endpoints:
    web:
      exposure:
        include: health,info
  endpoint:
    health:
      show-details: when-authorized

# WAL配置（从环境变量读取）
wal:
  base-path: ${WAL_BASE_PATH:/data/wal}
  max-file-size: ${WAL_MAX_FILE_SIZE:104857600}
  instance-id: ${WAL_INSTANCE_ID:default}

# Snapshot配置（从环境变量读取）
snapshot:
  base-path: ${SNAPSHOT_BASE_PATH:/data/snapshot}
  interval: ${SNAPSHOT_INTERVAL:300000}

# 撮合引擎配置（从环境变量读取）
match-engine:
  orderbook:
    update-depth: ${MATCH_ENGINE_ORDERBOOK_UPDATE_DEPTH:5}

# Disruptor配置（从环境变量读取）
disruptor:
  buffer-size: ${DISRUPTOR_BUFFER_SIZE:4096}
  wait-strategy: ${DISRUPTOR_WAIT_STRATEGY:blocking}

# 日志配置
logging:
  level:
    root: INFO
    com.spark.match: INFO
  file:
    name: /logs/match-engine-service.log
    max-size: 100MB
    max-history: 30
